{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple kernel to add two arrays\n",
    "mod = SourceModule(\"\"\"\n",
    "__global__ void add_arrays(float *a, float *b, float *result, int n)\n",
    "{\n",
    "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    if (idx < n)\n",
    "        result[idx] = a[idx] + b[idx];\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use Python lists instead of NumPy arrays\n",
    "a = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "b = [10.0, 20.0, 30.0, 40.0, 50.0]\n",
    "n = len(a)\n",
    "\n",
    "# Convert Python lists to byte arrays for GPU processing\n",
    "a_bytes = bytearray(struct.pack('%sf' % len(a), *a))\n",
    "b_bytes = bytearray(struct.pack('%sf' % len(b), *b))\n",
    "result_bytes = bytearray(n * 4)  # 4 bytes per float\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Allocate GPU memory\n",
    "a_gpu = cuda.mem_alloc(len(a_bytes))\n",
    "b_gpu = cuda.mem_alloc(len(b_bytes))\n",
    "result_gpu = cuda.mem_alloc(len(result_bytes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Transfer data to the GPU\n",
    "cuda.memcpy_htod(a_gpu, a_bytes)\n",
    "cuda.memcpy_htod(b_gpu, b_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Execute the kernel\n",
    "add_arrays = mod.get_function(\"add_arrays\")\n",
    "add_arrays(a_gpu, b_gpu, result_gpu, np.int32(n), block=(n, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fetch the result back to CPU\n",
    "cuda.memcpy_dtoh(result_bytes, result_gpu)\n",
    "result = struct.unpack('%sf' % n, result_bytes)\n",
    "\n",
    "print(\"Result:\", result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
